---
title: "Analysis"
author: "Freddie J. Heather"
date: "`r Sys.Date()`"
output: html_document
---

# Set-up

## Required packages

```{r packages}

if (!require("pacman")) install.packages("pacman")

pacman::p_load(
  "tidyverse",
  "arrow",
  "rstan",
  # "tidybayes", 
  "cowplot",
  "rlang",
  "posterior",
  "fitdistrplus", 
  "patchwork",
  "scales",
  "magick",
  "ggsci"
)

rstan_options(auto_write = TRUE) # avoid recompilation of stan files

select <- dplyr::select
`%!in%` <- Negate(`%in%`)

```

## Size bins

```{r}

rls_bin_breaks <- 
  c(2.5, 5.0, 7.5,  10.0, 12.5, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0, 
    50.0, 62.5, 75.0, 87.5, 100.0, 112.5, 125.0, 137.5, 150.0, 
    162.5, 175.0, 187.5, 200.0, 250.0, 300.0, 350.0, 400.0)

rls_bin_table <-
  tibble(size_class = c(0, rls_bin_breaks, 500)) %>% 
  mutate(
    size_indx  = 0:(length(size_class)-1),
    size_min = (size_class + lag(size_class))/2,
    size_max = lead(size_min)
  ) %>% 
  filter(size_class %in% c(rls_bin_breaks, 500))


rls_bin <- function(size) {
  
  rls_bin_table$size_class[.bincode(size, breaks = c(0, rls_bin_table$size_max))]
}

```

## Wrangling functions

```{r}

# outputs clean body size bin table given a vector of body sizes
get_bintable <- function(size_vector){
  
  sizebins <- 
    size_vector %>% 
    unique() %>% 
    c(0) %>%
    sort()
  
  tibble(size_class = sizebins) %>% 
    mutate(size_indx = 0:(nrow(.)-1),
           size_min = (size_class + lag(size_class))/2,
           size_max = lead(size_min)) %>% 
    filter(size_class != 0) %>% 
    mutate(size_max = case_when(size_class == max(sizebins) ~ size_class + (size_class-size_min), 
                                TRUE ~ size_max))
}

# takes population number, size_class, and n, outputs clean table with population id
clean_data <- function(count_table, 
                       sizes = "size_class", 
                       count = "n"){
  
  sizebin_tbl <- 
    count_table %>% 
    pull(!!sizes) %>% 
    get_bintable()
  
  popln_tbl <- 
    count_table %>% 
    select(population) %>% 
    distinct() %>% 
    mutate(population_indx = row_number())
  
  count_table %>% 
    rename(size_class := !!sizes) %>% 
    left_join(popln_tbl, by = join_by(population)) %>% 
    left_join(sizebin_tbl, by = join_by(size_class)) %>% 
    add_count(population_indx, wt = n, name = "population_n") %>% 
    arrange(population_indx, size_indx) %>%
    mutate(p = n/population_n) %>% 
    mutate(row = 1:n()) %>% 
    mutate(min_row = min(row), 
           max_row = max(row),
           .by = population_indx) 
  
}

```

## Data import

### Binned data

```{r}

rls_pop_level <- "gridcell"
rls_min_bins  <- 4
rls_min_count <- 200

rls_obs_data_filename <- 
  paste("input/data/cleaned/rls_obs_data", 
        rls_pop_level, 
        rls_min_bins, 
        rls_min_count, 
        sep = "_") %>% 
  paste0(".csv")

if(!file.exists(rls_obs_data_filename)){
  
  read_parquet("input/data/raw/data_obs_cleaned.parquet") %>% 
    left_join(read_parquet("input/data/raw/survey_list_m1_aus.parquet"), 
              by = join_by(survey_id)) %>% 
    mutate(lat_grid = round(latitude), 
           lon_grid = round(longitude), 
           gridcell = paste(lat_grid, lon_grid, sep = "_"), 
           population = paste(species_name, !!sym(rls_pop_level), sep = "__")) %>% 
    count(population, species_name, size_class, wt = n) %>% 
    add_count(population, name = "n_sizebins") %>% 
    add_count(population, wt = n, name = "population_n") %>%
    filter(n_sizebins >= rls_min_bins,
           population_n >= rls_min_count) %>%
    arrange(desc(population_n)) %>% 
    clean_data() %>% 
    write_csv(rls_obs_data_filename)
  
} 

rls_obs_data <- read_csv(rls_obs_data_filename, show_col_types = FALSE)

n_pops_rls <-
  rls_obs_data %>%
  pull(population) %>%
  n_distinct()

```

### Continuous data

```{r}

cbf_pop_level <- "location"
cbf_min_count <- 10

cbf_obs_data_filename <- 
  paste("input/data/cleaned/cbf_obs_data", 
        cbf_pop_level, 
        cbf_min_count, 
        sep = "_") %>% 
  paste0(".csv")

if(!file.exists(cbf_obs_data_filename)){
  
  read_csv("other/analysis/input/data/crypto.size.data.csv", 
           show_col_types = FALSE) %>%
    mutate(sl_cm = SL/10,
           tl_cm = TL/10) %>% # now in cm, not mm
    select(location = Location,
           species_name = sciname,
           # sl,
           tl_cm,
           # wt = W
    ) %>%
    filter(str_detect(species_name, "^[A-Z]{1}[a-z]+\\s[a-z]+$")) %>% 
    mutate(population = paste(species_name, !!sym(cbf_pop_level), sep = "__")) %>% 
    add_count(population,  name = "population_n") %>%
    filter(population_n >= cbf_min_count) %>%
    arrange(desc(population_n)) %>% 
    write_csv(cbf_obs_data_filename)
  
} 

cbf_obs_data <- read_csv(cbf_obs_data_filename, show_col_types = FALSE)

n_pops_cbf <-
  cbf_obs_data %>%
  pull(population) %>%
  n_distinct()

```

# Modelling

## Fitting

### Binned

```{r}


for(modelname in c("lognormal", "normal")){
  
  if(!file.exists(paste0("output/model_fits/fits_", modelname, ".csv"))){
    model_pars <- tibble(population = NA)
  } else {
    model_pars <- read_csv(paste0("output/model_fits/fits_", modelname, ".csv"), 
                           show_col_types = FALSE)
  }
  
  if(!file.exists(paste0("output/model_fits/convergence_", modelname, ".csv"))){
    model_convergence <- tibble()
  } else {
    model_convergence <- 
      read_csv(paste0("output/model_fits/convergence_", modelname, ".csv"), 
               show_col_types = FALSE)
  }
  
  if(!file.exists(paste0("output/model_fits/errors_", modelname, ".csv"))){
    model_errors <- c()
  } else {
    model_errors <- 
      read_csv(paste0("output/model_fits/errors_", modelname, ".csv"), 
               show_col_types = FALSE)
  }
  
  n_done <- 
    model_pars %>% 
    drop_na() %>% 
    pull(population) %>% 
    c(model_errors$population) %>% 
    unique() %>% 
    length()
  
  if(n_done < n_pops_rls){
    
    for(i in 1:n_pops_rls){
      
      current_data <-
        obs_data %>% 
        filter(population_indx == i) 
      
      current_pop <- 
        current_data %>% 
        pull(population) %>% 
        unique()
      
      if(!(current_pop %in% c(model_pars$population, 
                              model_errors$population))){
        
        inits <-
          current_data %>% 
          uncount(n) %>% 
          summarise(meanlog = mean(log(size_class)), 
                    sdlog = sd(log(size_class)))
        
        stan_data <- 
          list(
            B = length(unique(current_data$size_indx)),
            b_upr = current_data$size_max,
            b_lwr = current_data$size_min,
            n = current_data$n
          )
        
        fit <- 
          stan(file = paste0("input/stan_models/", modelname, ".stan"),
               data = stan_data,
               iter = 10000,
               warmup = 5000,
               chains = 3,
               refresh = 5000,
               cores = 1)
        
        if(!is.null(summary(fit)$summary)){
          
          rhat <- 
            summary(fit)$summary[,"Rhat"] %>% 
            as_tibble(rownames = "pars") %>% 
            mutate(population = unique(current_data$population)) %>% 
            rename(rhat = value)
          
          n_eff <- 
            summary(fit)$summary[,"n_eff"]%>% 
            as_tibble(rownames = "pars") %>% 
            mutate(population = unique(current_data$population)) %>% 
            rename(n_eff = value)
          
          model_convergence <- 
            bind_rows(
              model_convergence,
              left_join(rhat, n_eff, 
                        by = join_by(pars, population)))
          
          fit %>% 
            as_draws_df() %>% 
            as_tibble()
          
          current_pars <-
            fit %>% 
            as_draws_df() %>% 
            as_tibble() %>% 
            expand_grid(current_data) %>% 
            mutate(p = pnorm(size_max, mu, sigma) - pnorm(size_min, mu, sigma)) %>% 
            mutate(p = plnorm(size_max, meanlog, sdlog) - pnorm(size_min, meanlog, sdlog)) %>% 
            summarise(
              p_mean = mean(p), 
              p_median = median(p), 
              p_q5 = quantile(p, probs = 0.05),
              p_q95 = quantile(p, probs = 0.95), 
              .by = c(population, size_class, n, population_n)
            ) %>% 
            mutate(p_obs = n/population_n)
          
          model_pars <- 
            bind_rows(
              model_pars,
              current_pars
            )
          
          write_csv(model_pars, 
                    paste0("output/model_fits/pars_", modelname, ".csv"))
          write_csv(model_pars, 
                    paste0("output/model_fits/summary_", modelname, ".csv"))
          write_csv(model_convergence, 
                    paste0("output/model_fits/convergence_", modelname, ".csv"))
          
          cat(paste(i, "done."))
          
        } else  {
          
          model_errors <- 
            bind_rows(
              model_errors, 
              tibble(population = unique(current_data$population))
            )
          
          write_csv(model_errors, 
                    paste0("output/model_fits/errors_", modelname, ".csv"))
          
        }
      } else {
        
        
        cat(paste0("Population ", i, " already done.\n"))
      }
    }
  } else {
    cat(paste0("All ", n_pops_rls, " populations already ran for ", modelname, ".\n"))
  }
}

```

### Continuous

```{r}

for(cbf_modelname in c("lognormal", "normal")){
  
  cbf_model_pars <- 
    if(file.exists(paste0("output/model_fits/cbf_pars_", cbf_modelname, ".csv"))){
      read_csv(paste0("output/model_fits/cbf_pars_", cbf_modelname, ".csv"), 
               show_col_types = FALSE)
    } else {
      tibble()
    }
  
  
  cbf_n_done <- 
    cbf_model_pars %>% 
    drop_na() %>% 
    pull(population) %>% 
    unique() %>% 
    length()
  
  if(cbf_n_done < n_pops_cbf){
    
    if(!file.exists(paste0("output/model_fits/cbf_pars_", cbf_modelname, ".csv"))){
      model_pars <- tibble()
      model_convergence <- tibble()
      model_errors <- tibble()
      
      for(i in unique(cbf_obs_data$population)){
        
        cbf_current_data <-
          cbf_obs_data %>% 
          filter(population == i) 
        
        stan_data <- 
          list(
            n = unique(cbf_current_data$population_n), 
            y = cbf_current_data$tl_cm
          )
        
        fit <- 
          stan(file = paste0("input/stan_models/", cbf_modelname, "_continuous.stan"),
               data = stan_data,
               iter = 10000,
               warmup = 5000,
               chains = 3,
               refresh = 5000,
               cores = 1)
        
        if(!is.null(summary(fit)$summary)){
          
          rhat <- 
            summary(fit)$summary[,"Rhat"] %>% 
            as_tibble(rownames = "pars") %>% 
            mutate(population = unique(cbf_current_data$population)) %>% 
            rename(rhat = value)
          
          n_eff <- 
            summary(fit)$summary[,"n_eff"]%>% 
            as_tibble(rownames = "pars") %>% 
            mutate(population = unique(cbf_current_data$population)) %>% 
            rename(n_eff = value)
          
          model_convergence <- 
            bind_rows(
              model_convergence,
              left_join(rhat, n_eff, 
                        by = join_by(pars, population)))
          
          current_model_pars <- 
            fit %>% 
            as_draws_df() %>% 
            as_tibble() %>% 
            mutate(population = i)
          
          model_pars <- 
            bind_rows(
              model_pars,
              current_model_pars
            )
          
          cat(paste(i, "done."))
          
        } else  {
          
          model_errors <- 
            bind_rows(
              model_errors, 
              tibble(population = i)
            )
          
          
        }
      }
      
      write_csv(model_pars %>% drop_na(), 
                paste0("output/model_fits/cbf_pars_", cbf_modelname, ".csv"))
      write_csv(model_convergence, 
                paste0("output/model_fits/cbf_convergence_", cbf_modelname, ".csv"))
    }
    
  } else {
    cat(paste0("All ", n_pops_cbf, " populations already ran for ", cbf_modelname, ".\n"))
    
  } 
}

```


## Summarising 

### Nonconvergent populations

```{r}

# Removing the estimates of models that did not converge
nonconverge_pops <- function(modelname){
  paste0("output/model_fits/rls_convergence_", modelname, ".csv") %>% 
    read_csv(show_col_types = FALSE) %>% 
    filter(rhat > 1.1) %>% 
    pull(population) %>% 
    unique() 
}

```



```{r}
# 
# rls_fits <- 
#   read_csv("output/model_fits/rls_pars_lognormal.parquet", 
#            show_col_types = FALSE) %>% 
#   mutate(model = "lognormal") %>% 
#   filter(!(population %in% nonconverge_pops("lognormal"))) %>% 
#   bind_rows(
#     read_csv("output/model_fits/rls_pars_normal.par", 
#              show_col_types = FALSE) %>% 
#       mutate(model = "normal") %>% 
#       filter(!(population %in% nonconverge_pops("normal")))
#   ) %>% 
#   pivot_wider(names_from = c(model), 
#               values_from = c(p_mean:p_q95))
# 
# 
# cbf_fits <- 
#   read_csv("output/model_fits/cbf_pars_lognormal.csv", 
#            show_col_types = FALSE) %>% 
#   mutate(model = "lognormal") %>% 
#   filter(!(population %in% nonconverge_pops("lognormal"))) %>% 
#   bind_rows(
#     read_csv("output/model_fits/cbf_pars_normal.csv", 
#              show_col_types = FALSE) %>% 
#       mutate(model = "normal") %>% 
#       filter(!(population %in% nonconverge_pops("normal")))
#   ) %>% 
#   pivot_wider(names_from = c(model), 
#               values_from = c(p_mean:p_q95))


```

# Plotting

## Figure 1

```{r}

rls_pars_lognormal <- 
  read_parquet("output/model_fits/rls_pars_lognormal.parquet") %>%
  summarise(
    meanlog = median(meanlog), 
    sdlog = median(sdlog), 
    lp_lognormal = median(lp__),
    .by = population
  ) %>% 
  mutate(data = "rls") %>% 
  filter(!(population %in% nonconverge_pops("lognormal")))

rls_pars_normal <- 
  read_parquet("output/model_fits/rls_pars_normal.parquet") %>% 
  summarise(
    mu = mean(mu), 
    sigma = median(sigma), 
    lp_normal = median(lp__),
    .by = population
  ) %>% 
  mutate(data = "rls") %>% 
  filter(!(population %in% nonconverge_pops("normal")))

cbf_pars_lognormal <- 
  read_csv("output/model_fits/cbf_pars_lognormal.csv", 
           show_col_types = FALSE) %>%
  summarise(
    meanlog = median(meanlog), 
    sdlog = median(sdlog), 
    lp_lognormal = median(lp__),
    .by = population
  ) %>% 
  mutate(data = "cbf")

cbf_pars_normal <- 
  read_csv("output/model_fits/cbf_pars_normal.csv", 
           show_col_types = FALSE) %>%
  summarise(
    mu = mean(mu), 
    sigma = median(sigma), 
    lp_normal = median(lp__),
    .by = population
  ) %>% 
  mutate(data = "cbf") 

mean_sizes <- 
  rls_obs_data %>% 
  select(population, size_class, n) %>% 
  uncount(n) %>% 
  summarise(mean_size = mean(size_class),
            .by = population) %>% 
  bind_rows(
    cbf_obs_data %>% 
      summarise(mean_size = mean(tl_cm),
                .by = population)
  )

plot_data <- 
  bind_rows(
    full_join(
      rls_pars_normal,
      rls_pars_lognormal,
    ) %>% 
      mutate(ll_diff = lp_normal - lp_lognormal) %>% 
      mutate(normal_better = lp_normal>lp_lognormal), 
    full_join(
      cbf_pars_normal, 
      cbf_pars_lognormal,
    ) %>% 
      mutate(ll_diff = lp_normal - lp_lognormal) %>% 
      mutate(normal_better = lp_normal>lp_lognormal)
  ) %>% 
  mutate(normal_better = case_when(
    is.na(mu) ~ FALSE, 
    is.na(meanlog) ~ TRUE, 
    TRUE ~ normal_better
  )) %>% 
  mutate(cov = case_when(normal_better ~ sigma/mu, 
                         TRUE ~ sqrt(exp(sdlog)-1))) %>% 
  left_join(mean_sizes) %>% 
mutate(better_dist = ifelse(normal_better, "normal", "lognormal"), 
)

high_cov <- 
  plot_data %>% 
  filter(cov > 2) %>% 
  pull(population)

p1 <-
  plot_data %>% 
  filter(cov < 2) %>%
  ggplot() + 
  aes(
    x = mean_size, 
    y = cov, 
    pch = data,
    col = better_dist
  ) +
  geom_point(alpha = 1) +
  scale_x_continuous(trans = "log10", labels = label_number(suffix="cm")) +
  scale_shape_manual(values = c("rls" = 21, "cbf" = 24), 
                     labels = c("rls" = "Reef Life Survey (binned)",
                                "cbf" = "Cryptobenthic (continuous)")) +
  scale_color_manual(values = c("normal" = rgb(181, 144, 19, maxColorValue=255),
                                  "lognormal" = rgb(29, 84, 128, maxColorValue=255)),
    labels = c("normal" = "Normal preferred",
                              "lognormal" = "Lognormal preferred")) +
  labs(x = "Log mean size", 
       y = "Coefficient of variation") +
  theme_cowplot(20) +
  theme(legend.position = c(0.01, 1),
        legend.justification = c(0,1), 
        legend.background = element_rect(color = "black"),
        legend.margin=margin(0,10,10,10), 
        legend.title = element_blank())
p1

p2 <- 
  plot_data %>% 
  filter(cov < 2) %>%
  ggplot() +
  aes(
    x = cov, 
    fill = better_dist
  ) +
  scale_fill_manual(values = c("normal" = rgb(181, 144, 19, maxColorValue=255),
                                  "lognormal" = rgb(29, 84, 128, maxColorValue=255))) +
  geom_density(alpha = 0.3, col = "black") +
  coord_flip() +
  theme_void(20) +
  theme(legend.position = "none")


p3 <- p1 + p2 + plot_layout(ncol=2, widths=c(6,1)) + plot_annotation(tag_levels = 'A')
p3

ggsave(filename = paste0("manuscript/ms_figures/parameter_regression.png"),
       plot = p3,
       height = 20,
       width = 32,
       units = "cm")

```


## Populations with high COV

```{r}

rls_obs_data %>% 
  filter(population %in% high_cov) %>% 
  ggplot() +
  aes(x = size_class, 
      y = n) +
  geom_point() + 
  geom_path() + 
  facet_wrap(~population, scales = "free")

```

## Numerical calculation of the parameters

```{r}

plot_data2_rls <- 
  rls_obs_data %>% 
  select(population, size_class, n) %>% 
  uncount(n) %>% 
  summarise(
    mean = mean(size_class), 
    sd = sd(size_class), 
    logmean = mean(log(size_class)), 
    logsd = sd(log(size_class)), 
    .by = population
  ) %>% 
  mutate(cov1 = sd/mean, 
         cov2 = sqrt(exp(logsd)-1))  %>% 
  mutate(data = "rls")

plot_data2_cbf <- 
  cbf_obs_data %>% 
  mutate(size_cm = tl_cm) %>% 
  select(population, size_cm) %>% 
  summarise(
    mean = mean(size_cm), 
    sd = sd(size_cm), 
    logmean = mean(log(size_cm)), 
    logsd = sd(log(size_cm)), 
    .by = population
  ) %>% 
  mutate(cov1 = sd/mean, 
         cov2 = sqrt(exp(logsd)-1)) %>% 
  mutate(data = "cbf")

plot_data2 <- 
  bind_rows(plot_data2_rls, 
            plot_data2_cbf)

plot_data2 %>% 
  ggplot(aes(x = cov1)) +
  geom_density() +
  geom_density(aes(x = cov2), col = "red")


plot_data2 %>%
  ggplot() + 
  aes(
    x = mean, 
    y = cov1, 
    col = data
  ) +
  geom_point(alpha = 0.5) +
  scale_x_continuous(trans = "log10", labels = label_number(suffix="cm")) +
  scale_shape_manual(values = c(20, 21)) +
  labs(x = "Log mean size (cm)", 
       y = "Coefficient of variation") +
  theme_cowplot(20) +
  theme(legend.position = "none")


plot_data2 %>%
  ggplot() + 
  aes(
    x = mean, 
    y = cov2, 
    col = data
  ) +
  geom_point(alpha = 0.5) +
  scale_x_continuous(trans = "log10", labels = label_number(suffix="cm")) +
  scale_shape_manual(values = c(20, 21)) +
  labs(x = "Log mean size (cm)", 
       y = "Coefficient of variation") +
  theme_cowplot(20) +
  theme(legend.position = "none")


```

## Figure 2

```{r}

plotting_dists <- 
  rls_obs_data %>% 
  filter(population_indx < 10)

p1 <- 
  plotting_dists %>% 
  left_join(mean_sizes) %>% 
  mutate(scaled_size = size_class/mean_size) %>% 
  mutate(scaled_n = n/population_n) %>%
  ggplot(aes(x = size_class, y = n, color = population)) +
  scale_color_simpsons() +
  geom_line(aes(y = n)) +
  theme(legend.position = "none") +
  theme_cowplot(20) +
  labs(
    x = "Body size (cm)",
    y = "N"
  ) +
  theme(legend.position = "none")


p2 <- 
  plotting_dists %>% 
  left_join(mean_sizes) %>% 
  mutate(scaled_size = size_class/mean_size) %>% 
  mutate(scaled_n = n/population_n) %>%
  ggplot(aes(x = size_class, y = scaled_n, col = population)) +
  geom_line(aes(y = scaled_n)) +
  scale_color_simpsons() +
  theme(legend.position = "none") +
  theme_cowplot(20) +
  labs(
    x = "Body size (cm)",
    y = "Scaled N"
  ) +
  theme(legend.position = "none")

p3 <- 
  plotting_dists %>% 
  left_join(mean_sizes) %>% 
  mutate(scaled_size = size_class/mean_size) %>% 
  mutate(scaled_n = n/population_n) %>%
  ggplot(aes(x = scaled_size, y = scaled_n, col = population)) +
  geom_line(aes(y = scaled_n)) +
  scale_color_simpsons() +
  scale_x_continuous(label = label_number(suffix = "x")) +
  theme(legend.position = "none") +
  theme_cowplot(20) +
  labs(
    x = "Scaled body size",
    y = "Scaled N"
  )+
  theme(legend.position = "none")

p4 <- 
  plotting_dists %>% 
  left_join(mean_sizes) %>% 
  mutate(scaled_size = size_class/mean_size) %>% 
  mutate(scaled_n = n/population_n) %>%
  ggplot(aes(x = scaled_size, y = scaled_n, col = population)) +
  # geom_point() +
  geom_line(aes(y = scaled_n)) +
  scale_x_log10(label = label_number(suffix = "x")) +
  scale_y_log10() +
  scale_color_simpsons() +
  theme(legend.position = "none") +
  theme_cowplot(20) +
  labs(
    x = "Scaled body size (log)",
    y = "Scaled N (log)"
  )+
  theme(legend.position = "none")

rls_pars_median <- 
  plot_data %>% 
  drop_na() %>% 
  summarise(
    mu = median(mu),
    sigma = median(sigma),
    meanlog = median(meanlog),
    sdlog = median(sdlog)
  ) 

scale_size_vec <- function(size_vector, lower_limit = 1.25) {
  tibble(size = size_vector) %>% 
    filter(size > lower_limit) %>% 
    mutate(size = rls_bin(size)) %>%
    mutate(mean_size = mean(size)) %>% 
    mutate(scaled_size = size/mean_size) %>% 
    count(scaled_size) %>% 
    mutate(scaled_n = n/sum(n)) %>% 
    select(scaled_size, scaled_n)
}

plot_lines <- 
  scale_size_vec(rnorm(1e6, rls_pars_median$mu, rls_pars_median$sigma)) %>% 
  mutate(dist = "normal") %>% 
  bind_rows(
    scale_size_vec(rlnorm(1e6, rls_pars_median$meanlog, rls_pars_median$sdlog)) %>% 
      mutate(dist = "lognormal") 
  )


p5 <- 
  rls_obs_data %>% 
  bind_rows(cbf_obs_data) %>% 
  left_join(mean_sizes) %>% 
  left_join(plot_data %>% select(population, normal_better)) %>% 
  mutate(scaled_size = size_class/mean_size) %>% 
  mutate(scaled_n = n/population_n) %>%
  ggplot(aes(x = scaled_size, y = scaled_n)) +
  # geom_line(aes(y = scaled_n, group = population, col = normal_better), alpha = 0.1) +
  geom_line(aes(y = scaled_n, group = population), col = "grey70", alpha = 0.1) +
  geom_line(aes(col = dist), linewidth = 2, data = plot_lines) +
  scale_x_log10(label = label_number(suffix = "x")) +
  scale_y_log10() +
  # scale_linetype_manual(values = c("lognormal" = "solid", "normal" = "21")) +
  scale_color_manual(values = c("normal" = rgb(181, 144, 19, maxColorValue=255),
                                  "lognormal" = rgb(29, 84, 128, maxColorValue=255))) +
  theme_cowplot(20) +
  theme(legend.position = c(0.1,0.1), 
        legend.justification = c(0,0),
        legend.title = element_blank()) +
  labs(
    x = "Scaled body size (log)",
    y = "Scaled N (log)"
  )

p6 <- p1 + p2 + p3 + p4 - p5 + plot_layout(ncol=1)  + plot_annotation(tag_levels = 'A')

ggsave(filename = paste0("manuscript/ms_figures/comparing_distributions.png"),
       plot = p6,
       height = 35,
       width = 25,
       units = "cm")

```

# Output data

```{r}

common_spp <- rls_obs_data$species_name[rls_obs_data$species_name %in% cbf_obs_data$species_name] %>% unique()

rls_obs_data %>%  
  filter(species_name %in% common_spp) %>% 
  ggplot() +
  # geom_point(aes(x = size_class, y = p)) +
  geom_path(aes(x = size_class, y = p)) +
  facet_wrap(~species_name, scales = "free") +
  geom_density(aes(x = tl_cm), data = cbf_obs_data %>%  filter(species_name %in% common_spp), col = "red") 


```

## Number of species

```{r}
rls_nspp <- rls_obs_data$species_name %>% unique() %>% length()
cbf_nspp <- cbf_obs_data$species_name %>% unique() %>% length()
tot_nspp <- c(rls_obs_data$species_name, cbf_obs_data$species_name) %>% unique() %>% length()

```

COV estimates

```{r}

normal_cov <- plot_data %>% filter(better_dist == "normal") %>% pull(cov)
lognormal_cov <- plot_data %>% filter(better_dist == "lognormal") %>% pull(cov)

plot_data$cov %>% quantile(0.025)
plot_data$cov %>% median()
plot_data$cov %>% quantile(0.975)


plot_data %>% 
  count(data, better_dist)

1100/(1100+1989)

wilcox.test(normal_cov, lognormal_cov)

median(normal_cov)
median(lognormal_cov)

```

